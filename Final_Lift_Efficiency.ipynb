{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(filename='lift_detection.log', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "u3DxCd0m_lo6"
   },
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "previous_state = \"continue\"  \n",
    "class LiftDetection:\n",
    "    def __init__(self, class_ids, conf_level, thr_centers, frame_max, patience, alpha):\n",
    "        self.class_ids = class_ids\n",
    "        self.conf_level = conf_level\n",
    "        self.thr_centers = thr_centers\n",
    "        self.frame_max = frame_max\n",
    "        self.patience = patience\n",
    "        self.alpha = alpha\n",
    "        self.centers_old = {}\n",
    "        self.obj_id = 0\n",
    "        self.count_p = 0\n",
    "        self.lastKey = ''\n",
    "        logger.info(\"LiftDetection instance initialized with parameters: class_ids=%s, conf_level=%.2f, thr_centers=%d, frame_max=%d, patience=%d, alpha=%.2f\",class_ids, conf_level, thr_centers, frame_max, patience, alpha)\n",
    "\n",
    "    def update_tracking(self, obj_center, thr_centers, lastKey, frame, frame_max):\n",
    "        is_new = 0\n",
    "        lastpos = [(k, list(center.keys())[-1], list(center.values())[-1]) for k, center in self.centers_old.items()]\n",
    "        lastpos = [(i[0], i[2]) for i in lastpos if abs(i[1] - frame) <= frame_max]\n",
    "        previous_pos = [(k, centers) for k, centers in lastpos if (np.linalg.norm(np.array(centers) - np.array(obj_center)) < thr_centers)]\n",
    "        if previous_pos:\n",
    "            id_obj = previous_pos[0][0]\n",
    "            self.centers_old[id_obj][frame] = obj_center\n",
    "        else:\n",
    "            if lastKey:\n",
    "                last = int(lastKey.split('ID')[1])\n",
    "                id_obj = 'ID' + str(last + 1)\n",
    "            else:\n",
    "                id_obj = 'ID0'\n",
    "            is_new = 1\n",
    "            self.centers_old[id_obj] = {frame: obj_center}\n",
    "            lastKey = id_obj\n",
    "\n",
    "        return self.centers_old, id_obj, is_new, lastKey\n",
    "\n",
    "    def filter_tracks(self, centers, patience):\n",
    "        filter_dict = {}\n",
    "        for k, i in centers.items():\n",
    "            d_frames = i.items()\n",
    "            filter_dict[k] = dict(list(d_frames)[-patience:])\n",
    "        return filter_dict\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        cnt =0\n",
    "        class_names = open(\"coco.names\", \"r\")\n",
    "        class_names = class_names.read()\n",
    "        class_names = class_names.split(\"\\n\")\n",
    "        global tmp,previous_state\n",
    "        scale_percent = 100\n",
    "        ROI = frame[243:666, 97:774]\n",
    "        area_ROI = [np.array([(97, 243), (774, 243), (97, 666), (774, 666)], np.int32)]\n",
    "        result_message = \" \"\n",
    "        # Check if the frame is not empty and the dimensions are greater than zero\n",
    "        if ROI is not None and ROI.shape[0] > 0 and ROI.shape[1] > 0:\n",
    "            ROI = cv2.resize(ROI, (ROI.shape[1] * scale_percent // 100, ROI.shape[0] * scale_percent // 100), interpolation=cv2.INTER_AREA)\n",
    "            y_hat = model.predict(ROI, conf=self.conf_level, classes=self.class_ids, device=\"cpu\", verbose=False)\n",
    "\n",
    "            x, y, width, height = 243,97, 666, 774\n",
    "            mask = ROI.copy()\n",
    "            #cv2.rectangle(mask, (0, 0), (ROI.shape[1], ROI.shape[0]), (0, 0, 0), -1)\n",
    "            #cv2.rectangle(mask, (x, y), (x + width, y + height), (0, 0, 255), -1)\n",
    "\n",
    "            overlay = frame.copy()\n",
    "            cv2.polylines(overlay, pts = area_ROI, isClosed=True, color=(255,0,0), thickness= 2)\n",
    "            cv2.fillPoly(overlay, area_ROI, (255,0,0))\n",
    "            frame_with_mask = cv2.addWeighted(mask, 0.5, ROI, 0.5, 0)\n",
    "\n",
    "            boxes = y_hat[0].boxes.xyxy.cpu().numpy()\n",
    "            conf = y_hat[0].boxes.conf.cpu().numpy()\n",
    "            result = y_hat[0].boxes.data\n",
    "            result = pd.DataFrame(result)\n",
    "\n",
    "            positions_frame = pd.DataFrame(y_hat[0].cpu().numpy().boxes.data, columns=['xmin', 'ymin', 'xmax', 'ymax', 'conf', 'class'])\n",
    "\n",
    "            for ix, row in enumerate(positions_frame.iterrows()):\n",
    "                xmin, ymin, xmax, ymax, confidence, category, = row[1].astype('int')\n",
    "                center_x, center_y = int((xmax + xmin) / 2), int((ymax + ymin) / 2)\n",
    "                self.centers_old, id_obj, is_new, self.lastKey = self.update_tracking((center_x, center_y), self.thr_centers, self.lastKey, 0, self.frame_max)\n",
    "                logger.info(\"Object ID: %s detected at position (%d, %d)\", id_obj, center_x, center_y)\n",
    "                self.count_p += is_new\n",
    "\n",
    "                cv2.rectangle(frame_with_mask, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_with_mask, id_obj + ':' + str(np.round(confidence, 2)), (xmin, ymin - 10), cv2.FONT_HERSHEY_TRIPLEX, 0.8, (0, 255, 0), 1)\n",
    "\n",
    "            for index, rows in result.iterrows():\n",
    "                d = int(rows[5])\n",
    "                c = class_names[d]\n",
    "                cnt = c.count(\"person\")\n",
    "            if cnt > 0:\n",
    "                result_message = \"stop the  lift\"\n",
    "                if previous_state == \"continue\":\n",
    "                    logger.info(\"Stopping the lift due to person count: %d\", cnt)\n",
    "                    tmp = 1\n",
    "                    previous_state = \"stop\"\n",
    "            elif previous_state == \"stop\" and tmp == 0:\n",
    "                logger.info(\"Waiting 10 sec\")\n",
    "                time.sleep(10)\n",
    "                tmp = 1\n",
    "                result_message = \"continue the lift\"\n",
    "                logger.info(\"Continuing the lift as no person detected.\")\n",
    "                previous_state = \"continue\"\n",
    "            else:\n",
    "                result_message = \"continue the lift\"\n",
    "                tmp = 1\n",
    "                previous_state = \"continue\"\n",
    "                logger.info(\"Continuing the lift as no person detected.\")\n",
    "\n",
    "        return frame_with_mask, mask, result_message\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Create an instance of the LiftDetection class\n",
    "class_ids = [0]\n",
    "conf_level = 0.4\n",
    "thr_centers = 20\n",
    "frame_max = 10\n",
    "patience = 100\n",
    "alpha = 0.1\n",
    "lift_detection = LiftDetection(class_ids, conf_level, thr_centers, frame_max, patience, alpha)\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"videos/input8.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #logger.info(\"Processing frame %d\", count)\n",
    "    # Process the frame and get the result message, mask, and frame with mask\n",
    "    frame_with_mask, mask, result_message = lift_detection.process_frame(frame)\n",
    "\n",
    "    # Save the frames as images\n",
    "    cv2.imwrite(f\"frame_{count}.png\", frame)\n",
    "    cv2.imwrite(f\"mask_{count}.png\", mask)\n",
    "    cv2.imwrite(f\"frame_with_mask_{count}.png\", frame_with_mask)\n",
    "\n",
    "    # Display the frame with the result message\n",
    "    cv2.putText(frame_with_mask, result_message, (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Lift Detection\", frame_with_mask)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
